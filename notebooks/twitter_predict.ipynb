{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kate/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/kate/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/kate/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/kate/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from deeppavlov.core.common.file import read_json\n",
    "from deeppavlov import build_model, configs, train_model\n",
    "from deeppavlov.models.torch_bert.torch_transformers_classifier import TorchTransformersClassifierModel\n",
    "from deeppavlov.models.preprocessors.torch_transformers_preprocessor import TorchTransformersPreprocessor\n",
    "from joblib import load\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sarcsdet.models.count_model_metrics import *\n",
    "from sarcsdet.utils.train_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/Twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, 'twitter_tokenized.csv'), index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = read_json(configs.classifiers.rusentiment_bert)\n",
    "\n",
    "bert_config['dataset_reader']['x'] = 'quote'\n",
    "bert_config['dataset_reader']['y'] = 'target'\n",
    "bert_config['dataset_reader']['data_path'] = './'\n",
    "bert_config['dataset_reader']['train'] = 'train.csv'\n",
    "bert_config['dataset_reader']['valid'] = 'valid.csv'\n",
    "bert_config['dataset_reader']['test'] = 'test.csv'\n",
    "\n",
    "del bert_config['dataset_iterator']['split_seed']\n",
    "del bert_config['dataset_iterator']['field_to_split']\n",
    "del bert_config['dataset_iterator']['split_fields']\n",
    "del bert_config['dataset_iterator']['split_proportions']\n",
    "\n",
    "bert_config['metadata']['variables']['MODEL_PATH'] = '../data/Models/quotes/rubert/'\n",
    "\n",
    "del bert_config['chainer']['pipe'][-2:]\n",
    "del bert_config['chainer']['pipe'][1]\n",
    "bert_config['chainer']['pipe'][1]['in'] = 'y'\n",
    "bert_config['chainer']['pipe'][1]['depth'] = 2\n",
    "bert_config['chainer']['pipe'][2]['n_classes'] = 2\n",
    "bert_config['train']['metrics'] = [bert_config['train']['metrics'][-1]]\n",
    "bert_config['chainer']['out'] = ['y_pred_probas']\n",
    "bert_config['train']['epochs'] = 2\n",
    "bert_config['train']['batch_size'] = 32\n",
    "bert_config['train']['show_examples'] = True\n",
    "\n",
    "vocab_file = '{DOWNLOADS_PATH}/bert_models/rubert_cased_L-12_H-768_A-12_v1/vocab.txt'\n",
    "bert_config_file = \"{DOWNLOADS_PATH}/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_config.json\"\n",
    "pretrained_bert = \"{DOWNLOADS_PATH}/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\"\n",
    "\n",
    "bert_config['chainer']['pipe'][0]['vocab_file'] = vocab_file\n",
    "bert_config['chainer']['pipe'][1]['bert_config_file'] = bert_config_file\n",
    "bert_config['chainer']['pipe'][1]['pretrained_bert'] = pretrained_bert\n",
    "\n",
    "bert_config['chainer']['pipe'][2]['bert_config_file'] = bert_config_file\n",
    "bert_config['chainer']['pipe'][2]['pretrained_bert'] = pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/deeppavlov/models/bert/bert_classifier.py:84: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/deeppavlov/models/bert/bert_classifier.py:161: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/deeppavlov/models/bert/bert_classifier.py:92: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/deeppavlov/models/bert/bert_classifier.py:97: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-27 19:28:42.527 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/kate/Desktop/Sarcasm_Detection/data/Models/quotes/rubert/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kate/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/kate/Desktop/Sarcasm_Detection/data/Models/quotes/rubert/model\n"
     ]
    }
   ],
   "source": [
    "m = build_model(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:17,  5.84s/it]                       \n"
     ]
    }
   ],
   "source": [
    "preds_proba = []\n",
    "for batch in tqdm(chunks(df['quote'].values, 64), total=int(df.index.size / 64)):\n",
    "    preds_proba.append(m(batch))\n",
    "\n",
    "preds = np.concatenate(preds_proba)\n",
    "rubert_preds = (preds[:, 1] > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.436241610738255"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rubert_preds) / len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model SARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = read_json(configs.classifiers.rusentiment_bert)\n",
    "\n",
    "bert_config['dataset_reader']['x'] = 'rus_comment'\n",
    "bert_config['dataset_reader']['y'] = 'label'\n",
    "bert_config['dataset_reader']['data_path'] = './'\n",
    "bert_config['dataset_reader']['train'] = 'train.csv'\n",
    "bert_config['dataset_reader']['valid'] = 'valid.csv'\n",
    "bert_config['dataset_reader']['test'] = 'test.csv'\n",
    "\n",
    "del bert_config['dataset_iterator']['split_seed']\n",
    "del bert_config['dataset_iterator']['field_to_split']\n",
    "del bert_config['dataset_iterator']['split_fields']\n",
    "del bert_config['dataset_iterator']['split_proportions']\n",
    "\n",
    "bert_config['metadata']['variables']['MODEL_PATH'] = '../data/Models/reddit/rubert/'\n",
    "\n",
    "del bert_config['chainer']['pipe'][-2:]\n",
    "del bert_config['chainer']['pipe'][1]\n",
    "bert_config['chainer']['pipe'][1]['in'] = 'y'\n",
    "bert_config['chainer']['pipe'][1]['depth'] = 2\n",
    "bert_config['chainer']['pipe'][2]['n_classes'] = 2\n",
    "bert_config['train']['metrics'] = [bert_config['train']['metrics'][-1]]\n",
    "bert_config['chainer']['out'] = ['y_pred_probas']\n",
    "bert_config['train']['epochs'] = 2\n",
    "bert_config['train']['batch_size'] = 32\n",
    "bert_config['train']['show_examples'] = True\n",
    "\n",
    "vocab_file = '{DOWNLOADS_PATH}/bert_models/rubert_cased_L-12_H-768_A-12_v1/vocab.txt'\n",
    "bert_config_file = \"{DOWNLOADS_PATH}/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_config.json\"\n",
    "pretrained_bert = \"{DOWNLOADS_PATH}/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\"\n",
    "\n",
    "bert_config['chainer']['pipe'][0]['vocab_file'] = vocab_file\n",
    "bert_config['chainer']['pipe'][1]['bert_config_file'] = bert_config_file\n",
    "bert_config['chainer']['pipe'][1]['pretrained_bert'] = pretrained_bert\n",
    "\n",
    "bert_config['chainer']['pipe'][2]['bert_config_file'] = bert_config_file\n",
    "bert_config['chainer']['pipe'][2]['pretrained_bert'] = pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-27 19:55:21.184 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/kate/Desktop/Sarcasm_Detection/data/Models/reddit/rubert/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/kate/Desktop/Sarcasm_Detection/data/Models/reddit/rubert/model\n"
     ]
    }
   ],
   "source": [
    "m = build_model(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:15,  5.10s/it]                       \n"
     ]
    }
   ],
   "source": [
    "preds_proba = []\n",
    "for batch in tqdm(chunks(df['quote'].values, 64), total=int(df.index.size / 64)):\n",
    "    preds_proba.append(m(batch))\n",
    "\n",
    "preds = np.concatenate(preds_proba)\n",
    "rubert_preds = (preds[:, 1] > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5167785234899329"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rubert_preds) / len(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
